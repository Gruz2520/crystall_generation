{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset for fine-tuning with mp_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>material_id</th>\n",
       "      <th>formation_energy_per_atom</th>\n",
       "      <th>band_gap</th>\n",
       "      <th>pretty_formula</th>\n",
       "      <th>e_above_hull</th>\n",
       "      <th>elements</th>\n",
       "      <th>cif</th>\n",
       "      <th>spacegroup.number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37228</td>\n",
       "      <td>mp-1221227</td>\n",
       "      <td>-1.637460</td>\n",
       "      <td>0.2133</td>\n",
       "      <td>Na3MnCoNiO6</td>\n",
       "      <td>0.043001</td>\n",
       "      <td>['Co', 'Mn', 'Na', 'Ni', 'O']</td>\n",
       "      <td># generated using pymatgen\\r\\ndata_Na3MnCoNiO6...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19480</td>\n",
       "      <td>mp-974729</td>\n",
       "      <td>-0.314759</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Nd(Al2Cu)4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>['Al', 'Cu', 'Nd']</td>\n",
       "      <td># generated using pymatgen\\r\\ndata_Nd(Al2Cu)4\\...</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 material_id  formation_energy_per_atom  band_gap pretty_formula  \\\n",
       "0       37228  mp-1221227                  -1.637460    0.2133    Na3MnCoNiO6   \n",
       "1       19480   mp-974729                  -0.314759    0.0000     Nd(Al2Cu)4   \n",
       "\n",
       "   e_above_hull                       elements  \\\n",
       "0      0.043001  ['Co', 'Mn', 'Na', 'Ni', 'O']   \n",
       "1      0.000000             ['Al', 'Cu', 'Nd']   \n",
       "\n",
       "                                                 cif  spacegroup.number  \n",
       "0  # generated using pymatgen\\r\\ndata_Na3MnCoNiO6...                  8  \n",
       "1  # generated using pymatgen\\r\\ndata_Nd(Al2Cu)4\\...                139  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../data/mp_20/mp_20.csv\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input(row):\n",
    "    return f\"band_gap={row['band_gap']} spacegroup.number={row['spacegroup.number']}\"\n",
    "\n",
    "df['cif'] = df['cif'].str.replace('# generated using pymatgen\\n', '', regex=False)\n",
    "\n",
    "new_data = {\n",
    "    'input': df.apply(create_input, axis=1),\n",
    "    'output': df['cif']\n",
    "}\n",
    "\n",
    "df_for_llama = pd.DataFrame(new_data)\n",
    "df_for_llama.to_csv('../data/df_for_llama.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>band_gap=0.2132999999999998 spacegroup.number=8</td>\n",
       "      <td>data_Na3MnCoNiO6\\n_symmetry_space_group_name_H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>band_gap=0.0 spacegroup.number=139</td>\n",
       "      <td>data_Nd(Al2Cu)4\\n_symmetry_space_group_name_H-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             input  \\\n",
       "0  band_gap=0.2132999999999998 spacegroup.number=8   \n",
       "1               band_gap=0.0 spacegroup.number=139   \n",
       "\n",
       "                                              output  \n",
       "0  data_Na3MnCoNiO6\\n_symmetry_space_group_name_H...  \n",
       "1  data_Nd(Al2Cu)4\\n_symmetry_space_group_name_H-...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_llama.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SLICE dataset for fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>mat_id</th>\n",
       "      <th>prototype_id</th>\n",
       "      <th>location</th>\n",
       "      <th>formula</th>\n",
       "      <th>elements</th>\n",
       "      <th>spg</th>\n",
       "      <th>nsites</th>\n",
       "      <th>stress</th>\n",
       "      <th>energy_total</th>\n",
       "      <th>...</th>\n",
       "      <th>dos_ef</th>\n",
       "      <th>energy_corrected</th>\n",
       "      <th>e_above_hull</th>\n",
       "      <th>e_form</th>\n",
       "      <th>e_phase_separation</th>\n",
       "      <th>decomposition</th>\n",
       "      <th>in_nomad</th>\n",
       "      <th>cif</th>\n",
       "      <th>SLICE</th>\n",
       "      <th>SLICE PLUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61866</td>\n",
       "      <td>agm004511222</td>\n",
       "      <td>AB2C3D4_7_spg115</td>\n",
       "      <td>cgat_comp/quaternaries/AB2C3D4/runs/batch-000/...</td>\n",
       "      <td>Sr2Zn3Ge4Pd</td>\n",
       "      <td>['Sr', 'Zn', 'Ge', 'Pd']</td>\n",
       "      <td>115</td>\n",
       "      <td>10</td>\n",
       "      <td>[[3.0763032, 0.0, 0.0], [0.0, 3.0763032, 0.0],...</td>\n",
       "      <td>-35.283144</td>\n",
       "      <td>...</td>\n",
       "      <td>2.885905</td>\n",
       "      <td>-35.283146</td>\n",
       "      <td>0.025135</td>\n",
       "      <td>-0.440718</td>\n",
       "      <td>0.021063</td>\n",
       "      <td>Sr2Zn3Ge4Pd</td>\n",
       "      <td>True</td>\n",
       "      <td># generated using pymatgen\\ndata_Sr2Zn3Ge4Pd\\n...</td>\n",
       "      <td>Sr Sr Zn Zn Zn Ge Ge Ge Ge Pd 0 7 o o o 1 8 o ...</td>\n",
       "      <td>Sr Sr Zn Zn Zn Ge Ge Ge Ge Pd 0 7 o o o 1 8 o ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61867</td>\n",
       "      <td>agm003932735</td>\n",
       "      <td>ABC2_7003_spg71</td>\n",
       "      <td>extra/batch-3000/Cl/Cl2CrTc/xxx_02a-00_agm0039...</td>\n",
       "      <td>CrTcCl2</td>\n",
       "      <td>['Cr', 'Tc', 'Cl']</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>[[2.9210932, 0.0116612, 0.05841717], [0.011661...</td>\n",
       "      <td>-21.772225</td>\n",
       "      <td>...</td>\n",
       "      <td>3.483516</td>\n",
       "      <td>-21.772224</td>\n",
       "      <td>1.225197</td>\n",
       "      <td>0.181212</td>\n",
       "      <td>1.225197</td>\n",
       "      <td>CrCl3  Cr  Tc</td>\n",
       "      <td>True</td>\n",
       "      <td># generated using pymatgen\\ndata_CrTcCl2\\n_sym...</td>\n",
       "      <td>Cr Tc Cl Cl 0 2 + + o 0 1 o o o 1 2 o + o 1 3 ...</td>\n",
       "      <td>Cr Tc Cl Cl 0 2 + + o 0 1 o o o 1 2 o + o 1 3 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61868</td>\n",
       "      <td>agm003160492</td>\n",
       "      <td>AB2_0_spg139</td>\n",
       "      <td>extra/batch-003/Au/AuTl2/xxx_02a-00_agm0031604...</td>\n",
       "      <td>Tl2Au</td>\n",
       "      <td>['Tl', 'Au']</td>\n",
       "      <td>139</td>\n",
       "      <td>3</td>\n",
       "      <td>[[4.422527, -0.01632697, -3.91e-06], [-0.01632...</td>\n",
       "      <td>-8.074673</td>\n",
       "      <td>...</td>\n",
       "      <td>1.489964</td>\n",
       "      <td>-8.074674</td>\n",
       "      <td>0.026976</td>\n",
       "      <td>-0.021588</td>\n",
       "      <td>0.003966</td>\n",
       "      <td>Tl2Au</td>\n",
       "      <td>NaN</td>\n",
       "      <td># generated using pymatgen\\ndata_Tl2Au\\n_symme...</td>\n",
       "      <td>Tl Tl Au 0 1 + o o 0 1 o o o 0 2 + o + 1 2 o o +</td>\n",
       "      <td>Tl Tl Au 0 1 + o o 0 1 o o o 0 2 + o + 1 2 o o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61869</td>\n",
       "      <td>agm002371989</td>\n",
       "      <td>ABC2_18_spg123</td>\n",
       "      <td>substitutions/batch-005/Fe/FePt2Pu/xxx_02p-00_...</td>\n",
       "      <td>PuFePt2</td>\n",
       "      <td>['Fe', 'Pt', 'Pu']</td>\n",
       "      <td>123</td>\n",
       "      <td>4</td>\n",
       "      <td>[[4.6794424, 0.0, 0.0], [0.0, 4.7021456, 0.0],...</td>\n",
       "      <td>-34.758170</td>\n",
       "      <td>...</td>\n",
       "      <td>14.017008</td>\n",
       "      <td>-34.758170</td>\n",
       "      <td>0.669855</td>\n",
       "      <td>0.029511</td>\n",
       "      <td>0.669855</td>\n",
       "      <td>PuPt2  Fe</td>\n",
       "      <td>True</td>\n",
       "      <td># generated using pymatgen\\ndata_PuFePt2\\n_sym...</td>\n",
       "      <td>Pu Fe Pt Pt 0 1 o - o 2 3 o o -</td>\n",
       "      <td>Pu Fe Pt Pt 0 1 o - o 2 3 o o - i u y 1s 1s 1s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61870</td>\n",
       "      <td>agm001640577</td>\n",
       "      <td>ABCD2_2_spg123</td>\n",
       "      <td>cgat_prot/ABCD2_prot2_spg123/runs/batch-102/Zn...</td>\n",
       "      <td>SrZn2CdPd</td>\n",
       "      <td>['Sr', 'Zn', 'Pd', 'Cd']</td>\n",
       "      <td>123</td>\n",
       "      <td>5</td>\n",
       "      <td>[[3.8065994, 0.0, 0.0], [0.0, 3.8065994, 0.0],...</td>\n",
       "      <td>-11.628009</td>\n",
       "      <td>...</td>\n",
       "      <td>2.942810</td>\n",
       "      <td>-11.628009</td>\n",
       "      <td>0.182077</td>\n",
       "      <td>-0.253307</td>\n",
       "      <td>0.182077</td>\n",
       "      <td>SrZn9Pd2  SrCd2  SrZn3Pd2</td>\n",
       "      <td>True</td>\n",
       "      <td># generated using pymatgen\\ndata_SrZn2CdPd\\n_s...</td>\n",
       "      <td>Sr Zn Zn Cd Pd 0 4 o o + 0 3 o o o 0 3 o + o 0...</td>\n",
       "      <td>Sr Zn Zn Cd Pd 0 4 o o + 0 3 o o o 0 3 o + o 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5068739</th>\n",
       "      <td>61861</td>\n",
       "      <td>agm001651623</td>\n",
       "      <td>ABCD2_2_spg123</td>\n",
       "      <td>cgat_prot/ABCD2_prot2_spg123/runs/batch-103/Ca...</td>\n",
       "      <td>Sr2CaZnPd</td>\n",
       "      <td>['Sr', 'Zn', 'Ca', 'Pd']</td>\n",
       "      <td>123</td>\n",
       "      <td>5</td>\n",
       "      <td>[[1.4767605, 0.0, 0.0], [0.0, 1.4767605, 0.0],...</td>\n",
       "      <td>-12.761735</td>\n",
       "      <td>...</td>\n",
       "      <td>3.073766</td>\n",
       "      <td>-12.761735</td>\n",
       "      <td>0.217014</td>\n",
       "      <td>-0.182018</td>\n",
       "      <td>0.217014</td>\n",
       "      <td>Sr13Pd2  Ca2ZnPd  Sr2ZnPd  SrZn</td>\n",
       "      <td>True</td>\n",
       "      <td># generated using pymatgen\\ndata_Sr2CaZnPd\\n_s...</td>\n",
       "      <td>Sr Sr Ca Zn Pd 0 4 + o + 1 4 + + o 2 3 o - -</td>\n",
       "      <td>Sr Sr Ca Zn Pd 0 4 + o + 1 4 + + o 2 3 o - - i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5068740</th>\n",
       "      <td>61862</td>\n",
       "      <td>agm001403142</td>\n",
       "      <td>ABCD_1_spg216</td>\n",
       "      <td>cgat_prot/ABCD_prot1_spg216/runs/batch-001/Cr/...</td>\n",
       "      <td>MnCrCoRe</td>\n",
       "      <td>['Re', 'Mn', 'Co', 'Cr']</td>\n",
       "      <td>216</td>\n",
       "      <td>4</td>\n",
       "      <td>[[5.4412737, 0.0, 0.0], [0.0, 5.4412737, 0.0],...</td>\n",
       "      <td>-38.182897</td>\n",
       "      <td>...</td>\n",
       "      <td>2.123811</td>\n",
       "      <td>-38.182896</td>\n",
       "      <td>0.107962</td>\n",
       "      <td>0.041005</td>\n",
       "      <td>0.107962</td>\n",
       "      <td>MnCr15  Co2Re  Mn2Re  CoRe</td>\n",
       "      <td>True</td>\n",
       "      <td># generated using pymatgen\\ndata_MnCrCoRe\\n_sy...</td>\n",
       "      <td>Mn Cr Co Re 0 2 o o - 1 2 o o o 1 3 o o o</td>\n",
       "      <td>Mn Cr Co Re 0 2 o o - 1 2 o o o 1 3 o o o i u ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5068741</th>\n",
       "      <td>61863</td>\n",
       "      <td>agm015934710</td>\n",
       "      <td>AB3C4_37_spg47</td>\n",
       "      <td>m3gnet/alignn_009/In/In4Pr3Sm/xxx_02a-00_agm01...</td>\n",
       "      <td>Pr3SmIn4</td>\n",
       "      <td>['Pr', 'Sm', 'In']</td>\n",
       "      <td>47</td>\n",
       "      <td>8</td>\n",
       "      <td>[[2.2537906, 0.0, 0.0], [0.0, 2.4354684, 0.0],...</td>\n",
       "      <td>-33.952294</td>\n",
       "      <td>...</td>\n",
       "      <td>3.754129</td>\n",
       "      <td>-33.952293</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>-0.492613</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>Pr2SmIn3  Pr4SmIn5</td>\n",
       "      <td>NaN</td>\n",
       "      <td># generated using pymatgen\\ndata_Pr3SmIn4\\n_sy...</td>\n",
       "      <td>Pr Pr Pr Sm In In In In 0 7 + - o 1 4 + + o 2 ...</td>\n",
       "      <td>Pr Pr Pr Sm In In In In 0 7 + - o 1 4 + + o 2 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5068742</th>\n",
       "      <td>61864</td>\n",
       "      <td>agm004966293</td>\n",
       "      <td>ABC2D6_394_spg166</td>\n",
       "      <td>cgat_comp/quaternaries/ABC2D6/runs/batch-000/Z...</td>\n",
       "      <td>Sr2ZnCd6Pd</td>\n",
       "      <td>['Sr', 'Zn', 'Cd', 'Pd']</td>\n",
       "      <td>166</td>\n",
       "      <td>20</td>\n",
       "      <td>[[4.949308, 0.0, 0.0], [0.0, 4.949308, 0.0], [...</td>\n",
       "      <td>-35.504737</td>\n",
       "      <td>...</td>\n",
       "      <td>9.916821</td>\n",
       "      <td>-35.504738</td>\n",
       "      <td>0.109197</td>\n",
       "      <td>-0.236618</td>\n",
       "      <td>0.109197</td>\n",
       "      <td>SrCd2Pd  ZnPd  Sr3Cd11  SrZn3Pd2</td>\n",
       "      <td>True</td>\n",
       "      <td># generated using pymatgen\\ndata_Sr2ZnCd6Pd\\n_...</td>\n",
       "      <td>Sr Sr Sr Sr Zn Zn Cd Cd Cd Cd Cd Cd Cd Cd Cd C...</td>\n",
       "      <td>Sr Sr Sr Sr Zn Zn Cd Cd Cd Cd Cd Cd Cd Cd Cd C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5068743</th>\n",
       "      <td>61865</td>\n",
       "      <td>agm005821477</td>\n",
       "      <td>AB2C3_14_spg194</td>\n",
       "      <td>cgat_comp_2/ternaries/AB2C3/runs/batch-001/Ti/...</td>\n",
       "      <td>Ti2Ga3Rh</td>\n",
       "      <td>['Ti', 'Ga', 'Rh']</td>\n",
       "      <td>194</td>\n",
       "      <td>12</td>\n",
       "      <td>[[5.631944, 0.0, 0.0], [0.0, 5.631946, 0.0], [...</td>\n",
       "      <td>-71.289175</td>\n",
       "      <td>...</td>\n",
       "      <td>7.040172</td>\n",
       "      <td>-71.289180</td>\n",
       "      <td>0.025627</td>\n",
       "      <td>-0.570447</td>\n",
       "      <td>0.025627</td>\n",
       "      <td>TiGa2  TiGaRh2  Ti2Ga3</td>\n",
       "      <td>NaN</td>\n",
       "      <td># generated using pymatgen\\ndata_Ti2Ga3Rh\\n_sy...</td>\n",
       "      <td>Ti Ti Ti Ti Ga Ga Ga Ga Ga Ga Rh Rh 0 1 o o o ...</td>\n",
       "      <td>Ti Ti Ti Ti Ga Ga Ga Ga Ga Ga Rh Rh 0 1 o o o ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5068744 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0        mat_id       prototype_id  \\\n",
       "0             61866  agm004511222   AB2C3D4_7_spg115   \n",
       "1             61867  agm003932735    ABC2_7003_spg71   \n",
       "2             61868  agm003160492       AB2_0_spg139   \n",
       "3             61869  agm002371989     ABC2_18_spg123   \n",
       "4             61870  agm001640577     ABCD2_2_spg123   \n",
       "...             ...           ...                ...   \n",
       "5068739       61861  agm001651623     ABCD2_2_spg123   \n",
       "5068740       61862  agm001403142      ABCD_1_spg216   \n",
       "5068741       61863  agm015934710     AB3C4_37_spg47   \n",
       "5068742       61864  agm004966293  ABC2D6_394_spg166   \n",
       "5068743       61865  agm005821477    AB2C3_14_spg194   \n",
       "\n",
       "                                                  location      formula  \\\n",
       "0        cgat_comp/quaternaries/AB2C3D4/runs/batch-000/...  Sr2Zn3Ge4Pd   \n",
       "1        extra/batch-3000/Cl/Cl2CrTc/xxx_02a-00_agm0039...      CrTcCl2   \n",
       "2        extra/batch-003/Au/AuTl2/xxx_02a-00_agm0031604...        Tl2Au   \n",
       "3        substitutions/batch-005/Fe/FePt2Pu/xxx_02p-00_...      PuFePt2   \n",
       "4        cgat_prot/ABCD2_prot2_spg123/runs/batch-102/Zn...    SrZn2CdPd   \n",
       "...                                                    ...          ...   \n",
       "5068739  cgat_prot/ABCD2_prot2_spg123/runs/batch-103/Ca...    Sr2CaZnPd   \n",
       "5068740  cgat_prot/ABCD_prot1_spg216/runs/batch-001/Cr/...     MnCrCoRe   \n",
       "5068741  m3gnet/alignn_009/In/In4Pr3Sm/xxx_02a-00_agm01...     Pr3SmIn4   \n",
       "5068742  cgat_comp/quaternaries/ABC2D6/runs/batch-000/Z...   Sr2ZnCd6Pd   \n",
       "5068743  cgat_comp_2/ternaries/AB2C3/runs/batch-001/Ti/...     Ti2Ga3Rh   \n",
       "\n",
       "                         elements  spg  nsites  \\\n",
       "0        ['Sr', 'Zn', 'Ge', 'Pd']  115      10   \n",
       "1              ['Cr', 'Tc', 'Cl']   12       4   \n",
       "2                    ['Tl', 'Au']  139       3   \n",
       "3              ['Fe', 'Pt', 'Pu']  123       4   \n",
       "4        ['Sr', 'Zn', 'Pd', 'Cd']  123       5   \n",
       "...                           ...  ...     ...   \n",
       "5068739  ['Sr', 'Zn', 'Ca', 'Pd']  123       5   \n",
       "5068740  ['Re', 'Mn', 'Co', 'Cr']  216       4   \n",
       "5068741        ['Pr', 'Sm', 'In']   47       8   \n",
       "5068742  ['Sr', 'Zn', 'Cd', 'Pd']  166      20   \n",
       "5068743        ['Ti', 'Ga', 'Rh']  194      12   \n",
       "\n",
       "                                                    stress  energy_total  ...  \\\n",
       "0        [[3.0763032, 0.0, 0.0], [0.0, 3.0763032, 0.0],...    -35.283144  ...   \n",
       "1        [[2.9210932, 0.0116612, 0.05841717], [0.011661...    -21.772225  ...   \n",
       "2        [[4.422527, -0.01632697, -3.91e-06], [-0.01632...     -8.074673  ...   \n",
       "3        [[4.6794424, 0.0, 0.0], [0.0, 4.7021456, 0.0],...    -34.758170  ...   \n",
       "4        [[3.8065994, 0.0, 0.0], [0.0, 3.8065994, 0.0],...    -11.628009  ...   \n",
       "...                                                    ...           ...  ...   \n",
       "5068739  [[1.4767605, 0.0, 0.0], [0.0, 1.4767605, 0.0],...    -12.761735  ...   \n",
       "5068740  [[5.4412737, 0.0, 0.0], [0.0, 5.4412737, 0.0],...    -38.182897  ...   \n",
       "5068741  [[2.2537906, 0.0, 0.0], [0.0, 2.4354684, 0.0],...    -33.952294  ...   \n",
       "5068742  [[4.949308, 0.0, 0.0], [0.0, 4.949308, 0.0], [...    -35.504737  ...   \n",
       "5068743  [[5.631944, 0.0, 0.0], [0.0, 5.631946, 0.0], [...    -71.289175  ...   \n",
       "\n",
       "            dos_ef  energy_corrected  e_above_hull    e_form  \\\n",
       "0         2.885905        -35.283146      0.025135 -0.440718   \n",
       "1         3.483516        -21.772224      1.225197  0.181212   \n",
       "2         1.489964         -8.074674      0.026976 -0.021588   \n",
       "3        14.017008        -34.758170      0.669855  0.029511   \n",
       "4         2.942810        -11.628009      0.182077 -0.253307   \n",
       "...            ...               ...           ...       ...   \n",
       "5068739   3.073766        -12.761735      0.217014 -0.182018   \n",
       "5068740   2.123811        -38.182896      0.107962  0.041005   \n",
       "5068741   3.754129        -33.952293      0.002074 -0.492613   \n",
       "5068742   9.916821        -35.504738      0.109197 -0.236618   \n",
       "5068743   7.040172        -71.289180      0.025627 -0.570447   \n",
       "\n",
       "         e_phase_separation                       decomposition  in_nomad  \\\n",
       "0                  0.021063                        Sr2Zn3Ge4Pd       True   \n",
       "1                  1.225197                      CrCl3  Cr  Tc       True   \n",
       "2                  0.003966                              Tl2Au        NaN   \n",
       "3                  0.669855                          PuPt2  Fe       True   \n",
       "4                  0.182077          SrZn9Pd2  SrCd2  SrZn3Pd2       True   \n",
       "...                     ...                                 ...       ...   \n",
       "5068739            0.217014    Sr13Pd2  Ca2ZnPd  Sr2ZnPd  SrZn       True   \n",
       "5068740            0.107962         MnCr15  Co2Re  Mn2Re  CoRe       True   \n",
       "5068741            0.002074                 Pr2SmIn3  Pr4SmIn5        NaN   \n",
       "5068742            0.109197   SrCd2Pd  ZnPd  Sr3Cd11  SrZn3Pd2       True   \n",
       "5068743            0.025627             TiGa2  TiGaRh2  Ti2Ga3        NaN   \n",
       "\n",
       "                                                       cif  \\\n",
       "0        # generated using pymatgen\\ndata_Sr2Zn3Ge4Pd\\n...   \n",
       "1        # generated using pymatgen\\ndata_CrTcCl2\\n_sym...   \n",
       "2        # generated using pymatgen\\ndata_Tl2Au\\n_symme...   \n",
       "3        # generated using pymatgen\\ndata_PuFePt2\\n_sym...   \n",
       "4        # generated using pymatgen\\ndata_SrZn2CdPd\\n_s...   \n",
       "...                                                    ...   \n",
       "5068739  # generated using pymatgen\\ndata_Sr2CaZnPd\\n_s...   \n",
       "5068740  # generated using pymatgen\\ndata_MnCrCoRe\\n_sy...   \n",
       "5068741  # generated using pymatgen\\ndata_Pr3SmIn4\\n_sy...   \n",
       "5068742  # generated using pymatgen\\ndata_Sr2ZnCd6Pd\\n_...   \n",
       "5068743  # generated using pymatgen\\ndata_Ti2Ga3Rh\\n_sy...   \n",
       "\n",
       "                                                     SLICE  \\\n",
       "0        Sr Sr Zn Zn Zn Ge Ge Ge Ge Pd 0 7 o o o 1 8 o ...   \n",
       "1        Cr Tc Cl Cl 0 2 + + o 0 1 o o o 1 2 o + o 1 3 ...   \n",
       "2        Tl Tl Au 0 1 + o o 0 1 o o o 0 2 + o + 1 2 o o +    \n",
       "3                         Pu Fe Pt Pt 0 1 o - o 2 3 o o -    \n",
       "4        Sr Zn Zn Cd Pd 0 4 o o + 0 3 o o o 0 3 o + o 0...   \n",
       "...                                                    ...   \n",
       "5068739      Sr Sr Ca Zn Pd 0 4 + o + 1 4 + + o 2 3 o - -    \n",
       "5068740         Mn Cr Co Re 0 2 o o - 1 2 o o o 1 3 o o o    \n",
       "5068741  Pr Pr Pr Sm In In In In 0 7 + - o 1 4 + + o 2 ...   \n",
       "5068742  Sr Sr Sr Sr Zn Zn Cd Cd Cd Cd Cd Cd Cd Cd Cd C...   \n",
       "5068743  Ti Ti Ti Ti Ga Ga Ga Ga Ga Ga Rh Rh 0 1 o o o ...   \n",
       "\n",
       "                                                SLICE PLUS  \n",
       "0        Sr Sr Zn Zn Zn Ge Ge Ge Ge Pd 0 7 o o o 1 8 o ...  \n",
       "1        Cr Tc Cl Cl 0 2 + + o 0 1 o o o 1 2 o + o 1 3 ...  \n",
       "2        Tl Tl Au 0 1 + o o 0 1 o o o 0 2 + o + 1 2 o o...  \n",
       "3        Pu Fe Pt Pt 0 1 o - o 2 3 o o - i u y 1s 1s 1s...  \n",
       "4        Sr Zn Zn Cd Pd 0 4 o o + 0 3 o o o 0 3 o + o 0...  \n",
       "...                                                    ...  \n",
       "5068739  Sr Sr Ca Zn Pd 0 4 + o + 1 4 + + o 2 3 o - - i...  \n",
       "5068740  Mn Cr Co Re 0 2 o o - 1 2 o o o 1 3 o o o i u ...  \n",
       "5068741  Pr Pr Pr Sm In In In In 0 7 + - o 1 4 + + o 2 ...  \n",
       "5068742  Sr Sr Sr Sr Zn Zn Cd Cd Cd Cd Cd Cd Cd Cd Cd C...  \n",
       "5068743  Ti Ti Ti Ti Ga Ga Ga Ga Ga Ga Rh Rh 0 1 o o o ...  \n",
       "\n",
       "[5068744 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../data/alexandria/alex_full_slice.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'mat_id', 'prototype_id', 'location', 'formula',\n",
       "       'elements', 'spg', 'nsites', 'stress', 'energy_total', 'total_mag',\n",
       "       'band_gap_ind', 'band_gap_dir', 'dos_ef', 'energy_corrected',\n",
       "       'e_above_hull', 'e_form', 'e_phase_separation', 'decomposition',\n",
       "       'in_nomad', 'cif', 'SLICE', 'SLICE PLUS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено 10 файлов для объединения.\n",
      "Объединённый файл сохранён: ../data/alexandria/alex_full_slice.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def merge_csv_files(input_pattern, output_file):\n",
    "    \"\"\"\n",
    "    Объединяет несколько CSV-файлов в один.\n",
    "\n",
    "    :param input_pattern: Шаблон для поиска файлов (например, \"split_file_part_*.csv\").\n",
    "    :param output_file: Имя выходного файла.\n",
    "    \"\"\"\n",
    "    # Поиск всех файлов по шаблону\n",
    "    file_list = sorted(glob.glob(input_pattern))\n",
    "    if not file_list:\n",
    "        print(\"Файлы не найдены. Проверьте шаблон.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Найдено {len(file_list)} файлов для объединения.\")\n",
    "\n",
    "    # Чтение и объединение файлов\n",
    "    combined_df = pd.concat([pd.read_csv(file) for file in file_list], ignore_index=True)\n",
    "\n",
    "    # Сохранение результата\n",
    "    combined_df.to_csv(output_file, index=False)\n",
    "    print(f\"Объединённый файл сохранён: {output_file}\")\n",
    "\n",
    "# Параметры\n",
    "input_pattern = \"../data/alexandria/alexandria_split_file_part_*_slice.csv\"  # Шаблон для поиска файлов\n",
    "output_file = \"../data/alexandria/alex_full_slice.csv\"          # Имя выходного файла\n",
    "\n",
    "# Запуск функции\n",
    "merge_csv_files(input_pattern, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество непустых значений:\n",
      "band_gap_n: 5068744\n",
      "formation_energy: 5068744\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def fill_band_gap(df):\n",
    "    \"\"\"\n",
    "    Заполняет столбец 'band_gap' минимальным значением из доступных:\n",
    "    band_gap_ind, band_gap_dir, dir_gap, ind_gap.\n",
    "    Если все значения отсутствуют, оставляет NaN.\n",
    "    \"\"\"\n",
    "    # Создаём список столбцов, которые могут содержать ширину запрещённой зоны\n",
    "    band_gap_columns = ['band_gap_ind', 'band_gap_dir']\n",
    "    \n",
    "    # Выбираем минимальное значение из доступных столбцов\n",
    "    df['band_gap_n'] = df[band_gap_columns].min(axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def unify_formation_energy(df):\n",
    "    \"\"\"\n",
    "    Создаёт единый столбец 'formation_energy' из возможных вариантов:\n",
    "    formation_energy_per_atom, e_form, energy_per_atom.\n",
    "    Если значения конфликтуют, выбирается первое непустое.\n",
    "    \"\"\"\n",
    "    # Список возможных столбцов для энергии образования\n",
    "    formation_energy_columns = ['e_form']\n",
    "    \n",
    "    # Создаём новый столбец, выбирая первое непустое значение из списка\n",
    "    df['formation_energy'] = df[formation_energy_columns].bfill(axis=1).iloc[:, 0]\n",
    "    return df\n",
    "\n",
    "\n",
    "def count_non_empty_values(df, columns):\n",
    "    \"\"\"\n",
    "    Подсчитывает количество непустых значений в указанных столбцах.\n",
    "    Возвращает словарь с результатами.\n",
    "    \"\"\"\n",
    "    non_empty_counts = {col: df[col].notna().sum() for col in columns}\n",
    "    return non_empty_counts\n",
    "\n",
    "\n",
    "\n",
    "# Предполагаем, что у вас есть DataFrame `df`\n",
    "# df = pd.read_csv(\"your_dataset.csv\")  # загрузите ваш датасет\n",
    "\n",
    "# Шаг 1: Заполнить столбец band_gap\n",
    "df = fill_band_gap(df)\n",
    "\n",
    "# Шаг 2: Создать единый столбец formation_energy\n",
    "df = unify_formation_energy(df)\n",
    "\n",
    "# Шаг 3: Подсчитать количество непустых значений в результирующих столбцах\n",
    "result_columns = ['band_gap_n', 'formation_energy']\n",
    "counts = count_non_empty_values(df, result_columns)\n",
    "\n",
    "# Вывести результаты\n",
    "print(\"Количество непустых значений:\")\n",
    "for col, count in counts.items():\n",
    "    print(f\"{col}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['band_gap_n', 'formation_energy', 'SLICE', 'SLICE PLUS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['band_gap_n'].notna() & df['formation_energy'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5068744, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_input(row):\n",
    "    return f\"band_gap={row['band_gap_n']} e_form={row['formation_energy']}\"\n",
    "\n",
    "new_data = {\n",
    "    'input': df.apply(create_input, axis=1),\n",
    "    'output': df['SLICE']\n",
    "}\n",
    "\n",
    "df_for_llama = pd.DataFrame(new_data)\n",
    "df_for_llama = df_for_llama.dropna()\n",
    "df_for_llama.to_csv('../data/df_for_llama_bg_eform_slice.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Датасет успешно создан и разделен на train и validation части!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Функция для создания входных данных\n",
    "def create_input(row):\n",
    "    return f\"{row['band_gap_n']} {row['formation_energy']}\"\n",
    "\n",
    "# Создание нового датасета\n",
    "new_data = {\n",
    "    'input': df.apply(create_input, axis=1),\n",
    "    'output': df['SLICE']\n",
    "}\n",
    "\n",
    "df_for_llama = pd.DataFrame(new_data)\n",
    "\n",
    "# Удаление строк с пропущенными значениями\n",
    "df_for_llama = df_for_llama.dropna().drop_duplicates()\n",
    "\n",
    "# Разделение на обучающую и валидационную части\n",
    "train_df, valid_df = train_test_split(df_for_llama, test_size=0.1, random_state=42)\n",
    "\n",
    "# Сохранение в CSV файлы\n",
    "train_df.to_csv('../data/train_alex_full_gpt2.csv', index=False, header=True)\n",
    "valid_df.to_csv('../data/validation_alex_full_gpt2.csv', index=False, header=True)\n",
    "\n",
    "print(\"Датасет успешно создан и разделен на train и validation части!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1226941</th>\n",
       "      <td>0.0 0.093049474</td>\n",
       "      <td>Ac Ac Si Os 0 1 o o + 0 1 - o o 0 2 o o o 0 3 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2553221</th>\n",
       "      <td>0.0 -0.48427057</td>\n",
       "      <td>Pr Pt Pt Pt Pt Pt 0 3 o o o 0 1 o o o 1 2 o o ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4877144</th>\n",
       "      <td>0.0 1.8508282</td>\n",
       "      <td>Al C C 0 2 o - - 0 1 - o o 1 2 o - o 1 2 o o -</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891844</th>\n",
       "      <td>0.0 -0.56779855</td>\n",
       "      <td>K U Cu Cu Se Se Se Se 0 4 o - - 0 5 o o - 1 2 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860706</th>\n",
       "      <td>0.0 -0.7620643</td>\n",
       "      <td>Ce Ce Ce Ce Ce Ce Tm Tm Sb Sb Sb Sb Sb Sb 0 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573788</th>\n",
       "      <td>0.0 -2.574238</td>\n",
       "      <td>Sr Sr Sr Ca Mn Mn Cr O O O O O O O O O O 0 1 o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239845</th>\n",
       "      <td>0.0 0.31608596</td>\n",
       "      <td>Ba Ba As Ru Ru 0 2 + + o 0 1 o + - 0 3 o o - 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4938227</th>\n",
       "      <td>0.0 0.07110555</td>\n",
       "      <td>Th Th Sc Zn 0 1 - o + 0 1 o o o 0 3 o o o 0 2 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4314800</th>\n",
       "      <td>0.0 -0.29178774</td>\n",
       "      <td>Er Er Er Er Mg Hg Hg Hg Hg Hg Hg Hg 0 9 o o o ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696763</th>\n",
       "      <td>0.0 -0.49768546</td>\n",
       "      <td>Mo Ru F F 0 1 o o o 0 2 o o o 1 3 o o -</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4550982 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   input                                             output\n",
       "1226941  0.0 0.093049474  Ac Ac Si Os 0 1 o o + 0 1 - o o 0 2 o o o 0 3 ...\n",
       "2553221  0.0 -0.48427057  Pr Pt Pt Pt Pt Pt 0 3 o o o 0 1 o o o 1 2 o o ...\n",
       "4877144    0.0 1.8508282    Al C C 0 2 o - - 0 1 - o o 1 2 o - o 1 2 o o - \n",
       "891844   0.0 -0.56779855  K U Cu Cu Se Se Se Se 0 4 o - - 0 5 o o - 1 2 ...\n",
       "1860706   0.0 -0.7620643  Ce Ce Ce Ce Ce Ce Tm Tm Sb Sb Sb Sb Sb Sb 0 11...\n",
       "...                  ...                                                ...\n",
       "1573788    0.0 -2.574238  Sr Sr Sr Ca Mn Mn Cr O O O O O O O O O O 0 1 o...\n",
       "2239845   0.0 0.31608596  Ba Ba As Ru Ru 0 2 + + o 0 1 o + - 0 3 o o - 0...\n",
       "4938227   0.0 0.07110555  Th Th Sc Zn 0 1 - o + 0 1 o o o 0 3 o o o 0 2 ...\n",
       "4314800  0.0 -0.29178774  Er Er Er Er Mg Hg Hg Hg Hg Hg Hg Hg 0 9 o o o ...\n",
       "1696763  0.0 -0.49768546           Mo Ru F F 0 1 o o o 0 2 o o o 1 3 o o - \n",
       "\n",
       "[4550982 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6eee160d2ae45b79bb15cc527f8a19a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Error no file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory C:\\Programs\\crystall_generation\\Llama-3.2-3B-Instruct\\original.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m tokenizer_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPrograms\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcrystall_generation\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mLlama-3.2-3B-Instruct\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124moriginal\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Загрузка модели\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Загрузка токенизатора\u001b[39;00m\n\u001b[0;32m     11\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(tokenizer_path)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\auto\\auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    565\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    566\u001b[0m     )\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    570\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\modeling_utils.py:262\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    264\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\modeling_utils.py:3808\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3803\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m   3804\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError no file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_add_variant(SAFE_WEIGHTS_NAME,\u001b[38;5;250m \u001b[39mvariant)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m found in directory\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3805\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3806\u001b[0m         )\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3808\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m   3809\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError no file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_add_variant(WEIGHTS_NAME,\u001b[38;5;250m \u001b[39mvariant)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_add_variant(SAFE_WEIGHTS_NAME,\u001b[38;5;250m \u001b[39mvariant)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3810\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTF2_WEIGHTS_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTF_WEIGHTS_NAME\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFLAX_WEIGHTS_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m found in directory\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3811\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3812\u001b[0m         )\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(subfolder, pretrained_model_name_or_path)):\n\u001b[0;32m   3814\u001b[0m     archive_file \u001b[38;5;241m=\u001b[39m pretrained_model_name_or_path\n",
      "\u001b[1;31mOSError\u001b[0m: Error no file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory C:\\Programs\\crystall_generation\\Llama-3.2-3B-Instruct\\original."
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_path = \"C:\\Programs\\crystall_generation\\Llama-3.2-3B-Instruct\\original\"\n",
    "tokenizer_path = \"C:\\Programs\\crystall_generation\\Llama-3.2-3B-Instruct\\original\"\n",
    "\n",
    "# Загрузка модели\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "\n",
    "# Загрузка токенизатора\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Projects\\projects_python\\crystall_generation\\.venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e1ced0fba4a4115996472d0f0233249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04bf788942b4461cac945ecb02062381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "# Загрузка данных из CSV\n",
    "data = pd.read_csv('path/to/your/dataset.csv')\n",
    "\n",
    "# Преобразование в Dataset\n",
    "dataset = Dataset.from_pandas(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\projects_python\\crystall_generation\\.venv\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11700\\3178421298.py:17: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='33849' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    3/33849 05:23 < 3041:30:57, 0.00 it/s, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 26\u001b[0m\n\u001b[0;32m     17\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     18\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     19\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[0;32m     23\u001b[0m )\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Запуск обучения\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Projects\\projects_python\\crystall_generation\\.venv\\Lib\\site-packages\\transformers\\trainer.py:2171\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2169\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2172\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Projects\\projects_python\\crystall_generation\\.venv\\Lib\\site-packages\\transformers\\trainer.py:2531\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2524\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2525\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m   2526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2527\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[0;32m   2528\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[0;32m   2529\u001b[0m )\n\u001b[0;32m   2530\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m-> 2531\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2534\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2535\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2536\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2537\u001b[0m ):\n\u001b[0;32m   2538\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2539\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32md:\\Projects\\projects_python\\crystall_generation\\.venv\\Lib\\site-packages\\transformers\\trainer.py:3675\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[0;32m   3672\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   3674\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 3675\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3677\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[0;32m   3678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   3679\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3680\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   3681\u001b[0m ):\n",
      "File \u001b[1;32md:\\Projects\\projects_python\\crystall_generation\\.venv\\Lib\\site-packages\\transformers\\trainer.py:3731\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[0;32m   3729\u001b[0m         loss_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[0;32m   3730\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_kwargs}\n\u001b[1;32m-> 3731\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3732\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   3733\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   3734\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32md:\\Projects\\projects_python\\crystall_generation\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Projects\\projects_python\\crystall_generation\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Projects\\projects_python\\crystall_generation\\.venv\\Lib\\site-packages\\peft\\peft_model.py:1719\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.forward\u001b[1;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[0;32m   1717\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1718\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[1;32m-> 1719\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1720\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1721\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1722\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1723\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1724\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1725\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1726\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1727\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1728\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1730\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m _get_batch_size(input_ids, inputs_embeds)\n\u001b[0;32m   1731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1732\u001b[0m     \u001b[38;5;66;03m# concat prompt attention mask\u001b[39;00m\n",
      "File \u001b[1;32md:\\Projects\\projects_python\\crystall_generation\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Projects\\projects_python\\crystall_generation\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Projects\\projects_python\\crystall_generation\\.venv\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:197\u001b[0m, in \u001b[0;36mBaseTuner.forward\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[1;32m--> 197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Projects\\projects_python\\crystall_generation\\.venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:834\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **kwargs)\u001b[0m\n\u001b[0;32m    831\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m    833\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[1;32m--> 834\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    848\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    849\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[1;32md:\\Projects\\projects_python\\crystall_generation\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Projects\\projects_python\\crystall_generation\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Projects\\projects_python\\crystall_generation\\.venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:592\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[0;32m    580\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    581\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    582\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    589\u001b[0m         position_embeddings,\n\u001b[0;32m    590\u001b[0m     )\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 592\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    602\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    604\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[1;32md:\\Projects\\projects_python\\crystall_generation\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Projects\\projects_python\\crystall_generation\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Projects\\projects_python\\crystall_generation\\.venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:335\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    332\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[0;32m    334\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[1;32m--> 335\u001b[0m hidden_states, self_attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    346\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[0;32m    348\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[1;32md:\\Projects\\projects_python\\crystall_generation\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Projects\\projects_python\\crystall_generation\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Projects\\projects_python\\crystall_generation\\.venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:274\u001b[0m, in \u001b[0;36mLlamaAttention.forward\u001b[1;34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(hidden_states)\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    273\u001b[0m cos, sin \u001b[38;5;241m=\u001b[39m position_embeddings\n\u001b[1;32m--> 274\u001b[0m query_states, key_states \u001b[38;5;241m=\u001b[39m \u001b[43mapply_rotary_pos_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;66;03m# sin and cos are specific to RoPE models; cache_position needed for the static cache\u001b[39;00m\n\u001b[0;32m    278\u001b[0m     cache_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msin\u001b[39m\u001b[38;5;124m\"\u001b[39m: sin, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcos\u001b[39m\u001b[38;5;124m\"\u001b[39m: cos, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_position\u001b[39m\u001b[38;5;124m\"\u001b[39m: cache_position}\n",
      "File \u001b[1;32md:\\Projects\\projects_python\\crystall_generation\\.venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:172\u001b[0m, in \u001b[0;36mapply_rotary_pos_emb\u001b[1;34m(q, k, cos, sin, position_ids, unsqueeze_dim)\u001b[0m\n\u001b[0;32m    170\u001b[0m cos \u001b[38;5;241m=\u001b[39m cos\u001b[38;5;241m.\u001b[39munsqueeze(unsqueeze_dim)\n\u001b[0;32m    171\u001b[0m sin \u001b[38;5;241m=\u001b[39m sin\u001b[38;5;241m.\u001b[39munsqueeze(unsqueeze_dim)\n\u001b[1;32m--> 172\u001b[0m q_embed \u001b[38;5;241m=\u001b[39m (q \u001b[38;5;241m*\u001b[39m cos) \u001b[38;5;241m+\u001b[39m (\u001b[43mrotate_half\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m sin)\n\u001b[0;32m    173\u001b[0m k_embed \u001b[38;5;241m=\u001b[39m (k \u001b[38;5;241m*\u001b[39m cos) \u001b[38;5;241m+\u001b[39m (rotate_half(k) \u001b[38;5;241m*\u001b[39m sin)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m q_embed, k_embed\n",
      "File \u001b[1;32md:\\Projects\\projects_python\\crystall_generation\\.venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:147\u001b[0m, in \u001b[0;36mrotate_half\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    145\u001b[0m x1 \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, : x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    146\u001b[0m x2 \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m :]\n\u001b[1;32m--> 147\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    inputs = examples['input']\n",
    "    targets = examples['output']\n",
    "    \n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True)\n",
    "    labels = tokenizer(targets, max_length=512, truncation=True).input_ids\n",
    "    \n",
    "    # Установка -100 для padding tokens в labels\n",
    "    for i in range(len(labels)):\n",
    "        label = labels[i]\n",
    "        if len(label) < 512:\n",
    "            label += [-100] * (512 - len(label))\n",
    "        labels[i] = label\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../model/fine_tuned_Llama-2-7b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../model/fine_tuned_Llama-2-7b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,  # rank of the low-rank decomposition\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Projects\\projects_python\\crystall_generation\\.venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0522e0388fda4698926f3dca94db277e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "probability tensor contains either `inf`, `nan` or element < 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Генерация текста\u001b[39;00m\n\u001b[0;32m     13\u001b[0m input_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mband_gap=0.0 spacegroup.number=139\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 14\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n",
      "File \u001b[1;32md:\\Projects\\projects_python\\crystall_generation\\.venv\\Lib\\site-packages\\transformers\\pipelines\\text_generation.py:285\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[1;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[0;32m    283\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    284\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mlist\u001b[39m(chats), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Projects\\projects_python\\crystall_generation\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1362\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[0;32m   1355\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[0;32m   1356\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1359\u001b[0m         )\n\u001b[0;32m   1360\u001b[0m     )\n\u001b[0;32m   1361\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Projects\\projects_python\\crystall_generation\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1369\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[0;32m   1368\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[1;32m-> 1369\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1370\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[0;32m   1371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32md:\\Projects\\projects_python\\crystall_generation\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1269\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1267\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1268\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m-> 1269\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1270\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1271\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Projects\\projects_python\\crystall_generation\\.venv\\Lib\\site-packages\\transformers\\pipelines\\text_generation.py:383\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[1;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[0;32m    381\u001b[0m     generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config\n\u001b[1;32m--> 383\u001b[0m generated_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    384\u001b[0m out_b \u001b[38;5;241m=\u001b[39m generated_sequence\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32md:\\Projects\\projects_python\\crystall_generation\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Projects\\projects_python\\crystall_generation\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:2255\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   2247\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2248\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2249\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   2250\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2251\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2252\u001b[0m     )\n\u001b[0;32m   2254\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[1;32m-> 2255\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2256\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2260\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2262\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2263\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2265\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[0;32m   2266\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[0;32m   2267\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[0;32m   2268\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   2269\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2274\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[0;32m   2275\u001b[0m     )\n",
      "File \u001b[1;32md:\\Projects\\projects_python\\crystall_generation\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:3300\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   3298\u001b[0m     probs \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(next_token_scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   3299\u001b[0m     \u001b[38;5;66;03m# TODO (joao): this OP throws \"skipping cudagraphs due to ['incompatible ops']\", find solution\u001b[39;00m\n\u001b[1;32m-> 3300\u001b[0m     next_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   3301\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3302\u001b[0m     next_tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(next_token_scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: probability tensor contains either `inf`, `nan` or element < 0"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"path/to/save/fine-tuned-model\")\n",
    "tokenizer.save_pretrained(\"path/to/save/fine-tuned-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\igorg\\AppData\\Roaming\\Python\\Python39\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:31<00:00, 15.50s/it]\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.66 GiB is allocated by PyTorch, and 1.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m input_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mband_gap=0.0 spacegroup.number=139\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m----> 5\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-generation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mPrograms\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mcrystall_generation\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mmodels\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mllama\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m result \u001b[38;5;241m=\u001b[39m nlp(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_text\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\pipelines\\__init__.py:1178\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m processor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1176\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocessor\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m processor\n\u001b[1;32m-> 1178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pipeline_class(model\u001b[38;5;241m=\u001b[39mmodel, framework\u001b[38;5;241m=\u001b[39mframework, task\u001b[38;5;241m=\u001b[39mtask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\pipelines\\text_generation.py:99\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 99\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_model_type(\n\u001b[0;32m    101\u001b[0m         TF_MODEL_FOR_CAUSAL_LM_MAPPING_NAMES \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m MODEL_FOR_CAUSAL_LM_MAPPING_NAMES\n\u001b[0;32m    102\u001b[0m     )\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprefix\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_params:\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;66;03m# This is very specific. The logic is quite complex and needs to be done\u001b[39;00m\n\u001b[0;32m    105\u001b[0m         \u001b[38;5;66;03m# as a \"default\".\u001b[39;00m\n\u001b[0;32m    106\u001b[0m         \u001b[38;5;66;03m# It also defines both some preprocess_kwargs and generate_kwargs\u001b[39;00m\n\u001b[0;32m    107\u001b[0m         \u001b[38;5;66;03m# which is why we cannot put them in their respective methods.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\pipelines\\base.py:985\u001b[0m, in \u001b[0;36mPipeline.__init__\u001b[1;34m(self, model, tokenizer, feature_extractor, image_processor, processor, modelcard, framework, task, args_parser, device, torch_dtype, binary_output, **kwargs)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;66;03m# We shouldn't call `model.to()` for models loaded with accelerate as well as the case that model is already on device\u001b[39;00m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    980\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m    982\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    983\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m hf_device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    984\u001b[0m ):\n\u001b[1;32m--> 985\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;66;03m# If the model can generate:\u001b[39;00m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;66;03m# 1 - create a local generation config. This is done to avoid side-effects on the model as we apply local\u001b[39;00m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;66;03m# tweaks to the generation config.\u001b[39;00m\n\u001b[0;32m    990\u001b[0m \u001b[38;5;66;03m# 2 - load the assistant model if it is passed.\u001b[39;00m\n\u001b[0;32m    991\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massistant_model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massistant_tokenizer \u001b[38;5;241m=\u001b[39m load_assistant_model(\n\u001b[0;32m    992\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant_model\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m), kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant_tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    993\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\modeling_utils.py:3162\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[0;32m   3158\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3159\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3160\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3161\u001b[0m         )\n\u001b[1;32m-> 3162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1343\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1340\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1341\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:903\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 903\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    907\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    908\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    913\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    914\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:903\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 903\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    907\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    908\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    913\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    914\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[1;31m[... skipping similar frames: Module._apply at line 903 (2 times)]\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:903\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 903\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    907\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    908\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    913\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    914\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:930\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 930\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    931\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    933\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1329\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1323\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1324\u001b[0m             device,\n\u001b[0;32m   1325\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1326\u001b[0m             non_blocking,\n\u001b[0;32m   1327\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1328\u001b[0m         )\n\u001b[1;32m-> 1329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1333\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1334\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1335\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.66 GiB is allocated by PyTorch, and 1.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# Генерация текста\n",
    "input_text = \"band_gap=0.0 spacegroup.number=139\"\n",
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline(\"text-generation\", model=\"C:\\Programs\\crystall_generation\\models\\llama\")\n",
    "\n",
    "result = nlp(\"input_text\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valid fine-tuning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for valid models we synthesised a small dataset with inputs using description of banging_gap & spacegroup.numbers. We assume that generated CIF files will be converted to pymatgen.Structure without any problems. So metric quality of model will be percent of converted structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>formation_energy_per_atom</th>\n",
       "      <th>band_gap</th>\n",
       "      <th>e_above_hull</th>\n",
       "      <th>spacegroup.number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>45229.000000</td>\n",
       "      <td>45229.000000</td>\n",
       "      <td>45229.000000</td>\n",
       "      <td>45229.000000</td>\n",
       "      <td>45229.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22614.183710</td>\n",
       "      <td>-1.214873</td>\n",
       "      <td>0.789139</td>\n",
       "      <td>0.017189</td>\n",
       "      <td>123.126843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13056.910572</td>\n",
       "      <td>1.027732</td>\n",
       "      <td>1.417502</td>\n",
       "      <td>0.023133</td>\n",
       "      <td>79.655043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.153569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11307.000000</td>\n",
       "      <td>-2.001845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>22614.000000</td>\n",
       "      <td>-0.806754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003469</td>\n",
       "      <td>139.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>33921.000000</td>\n",
       "      <td>-0.403862</td>\n",
       "      <td>1.133400</td>\n",
       "      <td>0.030189</td>\n",
       "      <td>194.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>45230.000000</td>\n",
       "      <td>0.079825</td>\n",
       "      <td>17.902300</td>\n",
       "      <td>0.079999</td>\n",
       "      <td>229.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  formation_energy_per_atom      band_gap  e_above_hull  \\\n",
       "count  45229.000000               45229.000000  45229.000000  45229.000000   \n",
       "mean   22614.183710                  -1.214873      0.789139      0.017189   \n",
       "std    13056.910572                   1.027732      1.417502      0.023133   \n",
       "min        0.000000                  -5.153569      0.000000      0.000000   \n",
       "25%    11307.000000                  -2.001845      0.000000      0.000000   \n",
       "50%    22614.000000                  -0.806754      0.000000      0.003469   \n",
       "75%    33921.000000                  -0.403862      1.133400      0.030189   \n",
       "max    45230.000000                   0.079825     17.902300      0.079999   \n",
       "\n",
       "       spacegroup.number  \n",
       "count       45229.000000  \n",
       "mean          123.126843  \n",
       "std            79.655043  \n",
       "min             1.000000  \n",
       "25%            57.000000  \n",
       "50%           139.000000  \n",
       "75%           194.000000  \n",
       "max           229.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Статистические характеристики из датасета\n",
    "stats = {\n",
    "    'band_gap': {'mean': 0.789139, 'std': 1.417502, 'min': 0.0, 'max': 17.902300},\n",
    "    'spacegroup.number': {'min': 1, 'max': 229}\n",
    "}\n",
    "\n",
    "# Генерация 100 случайных значений\n",
    "np.random.seed(42)  # Фиксируем seed для воспроизводимости\n",
    "\n",
    "# Генерация значений для band_gap (нормальное распределение)\n",
    "band_gap = np.clip(\n",
    "    np.random.normal(stats['band_gap']['mean'], stats['band_gap']['std'], 100),\n",
    "    stats['band_gap']['min'],\n",
    "    stats['band_gap']['max']\n",
    ")\n",
    "\n",
    "# Генерация значений для spacegroup.number (равномерное распределение)\n",
    "spacegroup_number = np.random.randint(stats['spacegroup.number']['min'], stats['spacegroup.number']['max'] + 1, 100)\n",
    "\n",
    "# Формирование строк input\n",
    "inputs = [\n",
    "    f\"band_gap={bg:.4f} spacegroup.number={sg}\"\n",
    "    for bg, sg in zip(band_gap, spacegroup_number)\n",
    "]\n",
    "\n",
    "# Создание DataFrame для сохранения результатов\n",
    "synthetic_data = pd.DataFrame({'input': inputs})\n",
    "\n",
    "# Сохранение в CSV файл\n",
    "synthetic_data.to_csv('../data/banchmark/synthetic_inputs.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>band_gap=1.4932 spacegroup.number=137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>band_gap=0.5931 spacegroup.number=62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   input\n",
       "0  band_gap=1.4932 spacegroup.number=137\n",
       "1   band_gap=0.5931 spacegroup.number=62"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's take 100 samples from mp_20 dataset for comparison between synthesed and real data for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_sample = df_for_llama.sample(n=100)\n",
    "remaining_data = df_for_llama.drop(real_sample.index)\n",
    "\n",
    "real_sample[['input']].to_csv('../data/banchmark/real_inputs.csv', index=False)\n",
    "\n",
    "# Сохранение оставшихся данных в CSV файл\n",
    "remaining_data.to_csv('../data/df_for_llama_m100.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>band_gap=0.2132999999999998 spacegroup.number=8</td>\n",
       "      <td>data_Na3MnCoNiO6\\n_symmetry_space_group_name_H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>band_gap=0.0 spacegroup.number=139</td>\n",
       "      <td>data_Nd(Al2Cu)4\\n_symmetry_space_group_name_H-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             input  \\\n",
       "0  band_gap=0.2132999999999998 spacegroup.number=8   \n",
       "1               band_gap=0.0 spacegroup.number=139   \n",
       "\n",
       "                                              output  \n",
       "0  data_Na3MnCoNiO6\\n_symmetry_space_group_name_H...  \n",
       "1  data_Nd(Al2Cu)4\\n_symmetry_space_group_name_H-...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remaining_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymatgen.core.structure import Structure\n",
    "from pymatgen.io.cif import CifParser\n",
    "from transformers import pipeline\n",
    "\n",
    "def validate_cif(real_csv, synthetic_csv, model_path):\n",
    "    # Загрузка модели\n",
    "    generator = pipeline(\"text-generation\", model=model_path)\n",
    "\n",
    "    def process_dataset(csv_file, dataset_type):\n",
    "        # Загрузка CSV файла\n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        results = []\n",
    "        successful_count = 0\n",
    "\n",
    "        for idx, row in df.iterrows():\n",
    "            input_text = row['input']\n",
    "            \n",
    "            # Генерация CIF строки с помощью модели\n",
    "            generated_cif = generator(input_text, max_length=500)[0]['generated_text']\n",
    "            \n",
    "            try:\n",
    "                # Попытка преобразовать CIF в структуру pymatgen\n",
    "                structure = Structure.from_str(generated_cif, fmt=\"cif\")\n",
    "                conclusion = \"Successful\"\n",
    "                successful_count += 1\n",
    "            except Exception as e:\n",
    "                # Если возникла ошибка, считаем генерацию неудачной\n",
    "                conclusion = \"Failed\"\n",
    "\n",
    "            # Добавляем результат в список\n",
    "            results.append({\n",
    "                'input': input_text,\n",
    "                'generated_cif': generated_cif,\n",
    "                'conclusion': conclusion\n",
    "            })\n",
    "\n",
    "        # Создание DataFrame с результатами\n",
    "        result_df = pd.DataFrame(results)\n",
    "        \n",
    "        # Сохранение результатов в CSV файл\n",
    "        result_df.to_csv(f'{dataset_type}_validation_results.csv', index=False)\n",
    "        \n",
    "        # Подсчет процента успешных генераций\n",
    "        success_rate = (successful_count / len(df)) * 100\n",
    "        \n",
    "        return result_df, success_rate\n",
    "\n",
    "    # Обработка реальных данных\n",
    "    real_results, real_success_rate = process_dataset(real_csv, 'real')\n",
    "\n",
    "    # Обработка синтезированных данных\n",
    "    synthetic_results, synthetic_success_rate = process_dataset(synthetic_csv, 'synthetic')\n",
    "\n",
    "    # Вывод результатов\n",
    "    print(f\"Real data success rate: {real_success_rate:.2f}%\")\n",
    "    print(f\"Synthetic data success rate: {synthetic_success_rate:.2f}%\")\n",
    "\n",
    "    return real_results, synthetic_results\n",
    "\n",
    "# Пример использования функции\n",
    "real_csv = 'real_inputs_100.csv'\n",
    "synthetic_csv = 'synthetic_inputs.csv'\n",
    "model_path = './fine_tuned_llama'  # Укажите путь к вашей fine-tuned модели\n",
    "\n",
    "real_results, synthetic_results = validate_cif(real_csv, synthetic_csv, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pymatgen.core.structure import Structure\n",
    "from transformers import pipeline\n",
    "\n",
    "def analyze_attempts(real_csv, synthetic_csv, model_path, attempts_list):\n",
    "    # Загрузка модели\n",
    "    generator = pipeline(\"text-generation\", model=model_path)\n",
    "\n",
    "    def process_dataset(csv_file, dataset_type):\n",
    "        # Загрузка CSV файла\n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        success_rates = []  # Для хранения процентов успешных генераций\n",
    "        \n",
    "        for attempts in attempts_list:\n",
    "            successful_count = 0\n",
    "\n",
    "            for idx, row in df.iterrows():\n",
    "                input_text = row['input']\n",
    "                success = False  # Флаг успеха для текущего input\n",
    "\n",
    "                for _ in range(attempts):\n",
    "                    # Генерация CIF строки с помощью модели\n",
    "                    generated_cif = generator(input_text, max_length=500)[0]['generated_text']\n",
    "\n",
    "                    try:\n",
    "                        # Попытка преобразовать CIF в структуру pymatgen\n",
    "                        structure = Structure.from_str(generated_cif, fmt=\"cif\")\n",
    "                        success = True  # Если успешно, выходим из цикла\n",
    "                        break\n",
    "                    except Exception:\n",
    "                        continue  # Если неудачно, пробуем снова\n",
    "\n",
    "                if success:\n",
    "                    successful_count += 1\n",
    "\n",
    "            # Подсчет процента успешных генераций\n",
    "            success_rate = (successful_count / len(df)) * 100\n",
    "            success_rates.append(success_rate)\n",
    "\n",
    "        return success_rates\n",
    "\n",
    "    # Обработка реальных данных\n",
    "    real_success_rates = process_dataset(real_csv, 'real')\n",
    "\n",
    "    # Обработка синтезированных данных\n",
    "    synthetic_success_rates = process_dataset(synthetic_csv, 'synthetic')\n",
    "\n",
    "    # Построение графика\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(attempts_list, real_success_rates, label='Real Data', marker='o')\n",
    "    plt.plot(attempts_list, synthetic_success_rates, label='Synthetic Data', marker='x')\n",
    "    \n",
    "    plt.title('Success Rate vs Number of Attempts')\n",
    "    plt.xlabel('Number of Attempts per Input')\n",
    "    plt.ylabel('Success Rate (%)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Сохранение графика в файл\n",
    "    plt.savefig('success_rate_vs_attempts.png')  # Сохраняем график в PNG файл\n",
    "    plt.show()\n",
    "\n",
    "    # Вывод данных в текстовом формате\n",
    "    with open('success_rates.txt', 'w') as f:\n",
    "        f.write(\"Number of Attempts: {}\\n\".format(attempts_list))\n",
    "        f.write(\"Real Data Success Rates (%): {}\\n\".format(real_success_rates))\n",
    "        f.write(\"Synthetic Data Success Rates (%): {}\\n\".format(synthetic_success_rates))\n",
    "\n",
    "    return real_success_rates, synthetic_success_rates\n",
    "\n",
    "# Пример использования функции\n",
    "real_csv = 'real_inputs_100.csv'\n",
    "synthetic_csv = 'synthetic_inputs.csv'\n",
    "model_path = './fine_tuned_llama'  # Укажите путь к вашей fine-tuned модели\n",
    "attempts_list = [1, 2, 3, 5, 10]  # Список количества попыток\n",
    "\n",
    "real_success_rates, synthetic_success_rates = analyze_attempts(real_csv, synthetic_csv, model_path, attempts_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
